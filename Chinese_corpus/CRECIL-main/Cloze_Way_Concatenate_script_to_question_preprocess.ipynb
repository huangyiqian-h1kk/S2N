{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33a8b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "import zhon\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from transformers import set_seed\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import TFAutoModelForMaskedLM\n",
    "from transformers import BertForPreTraining, BertForMaskedLM, BertConfig\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.optim import AdamW\n",
    "import argparse, torch, datasets, ast, operator, gc, os\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import csv\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c637466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=1024, out_features=21128, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='search for best template according to dev set')\n",
    "parser.add_argument('--max_len', default=512, type=int, help=\"max sequence length\")\n",
    "parser.add_argument('--model', default='/home/lr/h1k/KNN-BERT-main/csi_sequetial_fine_tuning//MLM_task_tuned_models_for _datasets_PPL/MLM_tuned_roberta_large_JY_te+JY_Tr+CSI_tr/', type=str, help=\"pretrained model\")\n",
    "#parser.add_argument('--model', default='./chinese_roberta_wwm_large_ext_pytorch/')\n",
    "parser.add_argument('--result_output_dir', default='/home/lr/h1k/KNN-BERT-main/csi_sequetial_fine_tuning/Tune_on_CSI/csi_output/ppl_results/', type=str, help=\"output directory\")\n",
    "parser.add_argument('--tokenizer', default='/home/lr/h1k/KNN-BERT-main/csi_sequetial_fine_tuning/MLM_task_tuned_models_for _datasets_PPL/MLM_tuned_roberta_large_JY_te+JY_Tr+CSI_tr/', type=str, help=\"tokenizer\")\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# 加载模型和分词器\n",
    "model = BertForMaskedLM.from_pretrained(args.model)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(f'{args.tokenizer}')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#model = torch.nn.DataParallel(model)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6df9e43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"My_home.json\") as f:\n",
    "    data=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acfce833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['episodes'][0]['episode_id'].strip(\"ep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd7c0bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['episodes'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d72a9843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['episodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "508c1097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['episodes'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26fa5051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['episode_id', 'scenes'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['episodes'][0].keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7e0eaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['episodes'][0]['scenes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3aa8c47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'utterance_id': 'ep1_sc1_u1',\n",
       " 'speakers': '圆圆',\n",
       " 'transcript': '爸，动画片儿哪频道啊？',\n",
       " 'tokens': ['爸', '，', '动画片儿', '哪', '频道', '啊', '？', ''],\n",
       " 'character_entities': [['爸', 'jzg', 0]]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['episodes'][0]['scenes'][0]['utterances'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cdf4208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['episodes'][0]['scenes'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94f60113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['scene_id', 'utterances'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['episodes'][0]['scenes'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be815891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['utterance_id', 'speakers', 'transcript', 'tokens', 'character_entities'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['episodes'][0]['scenes'][0]['utterances'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7e0e4632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'爸，动画片儿哪频道啊？'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['episodes'][0]['scenes'][0]['utterances'][0]['transcript']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a42458ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'圆圆'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['episodes'][0]['scenes'][0]['utterances'][0]['speakers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "19557b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(path_from,path_to, vocab_file,vocab_bond):\n",
    "    \n",
    "    with open(path_from) as f:\n",
    "        dj=json.load(f)\n",
    "    \n",
    "    vf=open(vocab_file) \n",
    "    vocab= vf.readlines()\n",
    "    vocab=[i.strip('\\n') for i in vocab][vocab_bond[0]:vocab_bond[1]]\n",
    "        \n",
    "    name=path_from.split('/')[-1].strip('.csv')\n",
    "    data= context_window(dj['episodes'], vocab,name)\n",
    "    \n",
    "    with open(path_to, 'w') as f:\n",
    "        json.dump(data, f, ensure_ascii=False,indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d9038d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def examine_length(index_top, index_bottom, scene):\n",
    "    ref=''\n",
    "    utter=''\n",
    "    for i in range(index_top, index_bottom):\n",
    "        ref+=scene[i]['speakers']+scene[i]['transcript']\n",
    "        utter+= scene[i]['transcript']\n",
    "        window_num = ceil(len(ref)/512) \n",
    "    \n",
    "    limit=512-len(utter)\n",
    "    return window_num,limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "48f34493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_window(epis, vocab, name):\n",
    "    data_dict=dict()\n",
    "    data_dict[\"data\"]=list()\n",
    "    data_dict[\"version\"]=\"v1.0\",\n",
    "    \n",
    "    i_scene=0\n",
    "    for epi in epis:\n",
    "        print(\"epi\",epi['episode_id'])\n",
    "        scenes=epi[\"scenes\"]\n",
    "        for scene in scenes: \n",
    "            scene=scene['utterances']\n",
    "            window_num, s_limit = examine_length(0,len(scene),scene) \n",
    "            \n",
    "            if window_num==1:\n",
    "                utterances=[u['transcript'] for u in scene]\n",
    "                speakers=[u['speakers'] for u in scene]\n",
    "                masked_sets=get_masked_sets(speakers)\n",
    "                for m_speakers in masked_sets:\n",
    "                    paragraphs=lines_to_question(speakers,m_speakers, utterances, vocab, i_scene, name)\n",
    "                    data_dict[\"data\"].append({\"paragraphs\":paragraphs})\n",
    "                i_scene +=1\n",
    "                    \n",
    "            else:\n",
    "                norm_window_size=len(scene)//window_num\n",
    "                pointer=0\n",
    "                while pointer < len(scene)-5:\n",
    "                    pre_size=random.randint(min(6,norm_window_size-2),norm_window_size+1)\n",
    "                    window_size=min(pre_size, len(scene)-pointer)\n",
    "                    \n",
    "                    if not examine_length(pointer, pointer+window_size, scene)[0]==1:\n",
    "                        norm_window_size-=1\n",
    "                        continue\n",
    "                    utterances=[u['transcript'] for u in scene[pointer:pointer+window_size]]\n",
    "                    speakers=[u['speakers'] for u in scene[pointer:pointer+window_size]]\n",
    "                    masked_sets=get_masked_sets(speakers)\n",
    "                    \n",
    "                    for m_speakers in masked_sets:\n",
    "                        paragraphs=lines_to_question(speakers,m_speakers, utterances, vocab, i_scene, name)\n",
    "                        data_dict[\"data\"].append({\"paragraphs\":paragraphs})\n",
    "                    i_scene +=1\n",
    "                    pointer += window_size\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "16208e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noised_speaker(NAME):\n",
    "    name=NAME\n",
    "    while name==NAME or set(name)==1:\n",
    "        if random.random()<0.4:\n",
    "            mask=np.random.random(size = (len(name)))<0.5\n",
    "            name=''.join([name[i] if mask[i]==True else '□' for i in range(len(name))])\n",
    "        else:\n",
    "            name=''\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aca44439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_utter(SPEAKER,UTTER,T):\n",
    "    R1=(random.random()<T)*(SPEAKER!=\"\")\n",
    "    R2=random.random()<T\n",
    "    return R1*'：' + R2*'“' + UTTER + R2*'”'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "123b7392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masked_sets(s, aug_time=6):\n",
    "\n",
    "    #mask speakers\n",
    "    speakers=s.copy()\n",
    "    speaker_pointer=dict()\n",
    "    for i in range(len(speakers)):\n",
    "        if speakers[i] in speaker_pointer.keys():\n",
    "            speaker_pointer[speakers[i]].append(i)\n",
    "        else:\n",
    "            speaker_pointer[speakers[i]]=list()\n",
    "            speaker_pointer[speakers[i]].append(i)\n",
    "    \n",
    "    random_chance=1\n",
    "    unmask_pos=list()\n",
    "    while random_chance>=0 and len(unmask_pos)<aug_time:\n",
    "        res=[random.choice(l) for l in speaker_pointer.values()]\n",
    "        if not res in unmask_pos:\n",
    "            unmask_pos.append(res)\n",
    "        else:\n",
    "            random_chance-=1\n",
    "            \n",
    "    masked_speakers=list()        \n",
    "    for pos in unmask_pos:\n",
    "        this_list=[noised_speaker(speakers[i]) if not i in pos else speakers[i] for i in range(len(speakers))]\n",
    "        masked_speakers.append(this_list)\n",
    "        \n",
    "    return masked_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f0482e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lines_to_question(s,ms,u,v, index, name):\n",
    "    para=[{'id':name+\"_\"+str(index),'context':'','qas':[]}]\n",
    "    context, back, answer= concat_with_noise(set(s),ms,u,v)\n",
    "    para[-1][\"context\"]=context\n",
    "    \n",
    "    count=1\n",
    "    qas=list()\n",
    "\n",
    "    for i in range(len(u)+back):\n",
    "        question={'question':u[i],'id':name+\"_\"+str(index)+\"_\"+str(count),'answers':[{\"answer_start\":answer[s[i]],\"text\":s[i]}]}\n",
    "        count+=1\n",
    "        qas.append(question)\n",
    "        \n",
    "    para[-1][\"qas\"]=qas\n",
    "    return para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e026a173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_with_noise(speaker_set, ms, u, v, cloze_range=3, threshold1=0.5):\n",
    "    mspeakers=ms.copy()\n",
    "\n",
    "    cont, trace_back=cloze(u, mspeakers, cloze_range, threshold1)\n",
    "    speaker_answer=dict()\n",
    "    \n",
    "    for speaker in speaker_set:\n",
    "        speaker_answer[speaker]=cont.find(speaker)\n",
    " \n",
    "    return cont, trace_back, speaker_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c79b337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cloze(utter, m_speaker, cloze_range, threshold1):\n",
    "    sequence=''\n",
    "    pre_sequence=''\n",
    "    back=0\n",
    "    for i in range(len(m_speaker)):\n",
    "        ranint1=random.randint(0,cloze_range)\n",
    "        ranint2=random.randint(0,cloze_range)\n",
    "        random_threshold1= threshold1\n",
    "        pre_sequence+=m_speaker[i]+(m_speaker[i]!=\"\")*ranint1*tokenizer.mask_token + structure_utter(m_speaker[i],utter[i]+ tokenizer.mask_token*ranint2, random_threshold1) + tokenizer.sep_token\n",
    "        if len(pre_sequence)<512:\n",
    "            sequence=pre_sequence\n",
    "        else:\n",
    "            back=i-len(m_speaker)\n",
    "            break\n",
    "\n",
    "\n",
    "    input = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "    mask_token_index = torch.where(input == tokenizer.mask_token_id)[1]\n",
    "    token_logits = model(input.cuda()).logits\n",
    "    mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "    top_1_tokens = torch.topk(mask_token_logits, 1, dim=1).indices.squeeze(1)\n",
    "    \n",
    "    for i in range(len(mask_token_index)):\n",
    "        sequence=sequence.replace(tokenizer.mask_token, tokenizer.decode(top_1_tokens[i]),1)\n",
    "    sequence=sequence.replace(tokenizer.sep_token,'')\n",
    "    \n",
    "    return sequence, back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "605cb17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epi ep1\n",
      "epi ep2\n",
      "epi ep3\n",
      "epi ep4\n",
      "epi ep5\n",
      "epi ep6\n",
      "epi ep7\n",
      "epi ep8\n",
      "epi ep9\n",
      "epi ep10\n",
      "epi ep11\n",
      "epi ep12\n",
      "epi ep13\n",
      "epi ep14\n",
      "epi ep15\n",
      "epi ep16\n",
      "epi ep17\n",
      "epi ep18\n",
      "epi ep19\n",
      "epi ep20\n",
      "epi ep21\n",
      "epi ep22\n",
      "epi ep23\n",
      "epi ep24\n",
      "epi ep25\n",
      "epi ep26\n",
      "epi ep27\n",
      "epi ep28\n",
      "epi ep29\n",
      "epi ep30\n",
      "epi ep31\n",
      "epi ep32\n",
      "epi ep33\n",
      "epi ep34\n",
      "epi ep35\n",
      "epi ep36\n",
      "epi ep37\n",
      "epi ep38\n",
      "epi ep39\n",
      "epi ep40\n",
      "epi ep41\n",
      "epi ep42\n",
      "epi ep43\n",
      "epi ep44\n",
      "epi ep45\n",
      "epi ep46\n",
      "epi ep47\n",
      "epi ep48\n",
      "epi ep49\n",
      "epi ep50\n",
      "epi ep51\n",
      "epi ep52\n",
      "epi ep53\n",
      "epi ep54\n",
      "epi ep55\n",
      "epi ep56\n",
      "epi ep57\n",
      "epi ep58\n",
      "epi ep59\n",
      "epi ep60\n",
      "epi ep61\n",
      "epi ep62\n",
      "epi ep63\n",
      "epi ep64\n",
      "epi ep65\n",
      "epi ep66\n",
      "epi ep67\n",
      "epi ep68\n",
      "epi ep69\n",
      "epi ep70\n",
      "epi ep71\n",
      "epi ep72\n",
      "epi ep73\n",
      "epi ep74\n",
      "epi ep75\n",
      "epi ep76\n",
      "epi ep77\n",
      "epi ep78\n",
      "epi ep79\n",
      "epi ep80\n",
      "epi ep81\n",
      "epi ep82\n",
      "epi ep83\n",
      "epi ep84\n",
      "epi ep85\n",
      "epi ep86\n",
      "epi ep87\n",
      "epi ep88\n",
      "epi ep89\n",
      "epi ep90\n",
      "epi ep91\n",
      "epi ep92\n",
      "epi ep93\n",
      "epi ep94\n",
      "epi ep95\n",
      "epi ep96\n",
      "epi ep97\n",
      "epi ep98\n",
      "epi ep99\n",
      "epi ep100\n",
      "epi ep101\n",
      "epi ep102\n",
      "epi ep103\n",
      "epi ep104\n",
      "epi ep105\n",
      "epi ep106\n",
      "epi ep107\n",
      "epi ep108\n",
      "epi ep109\n",
      "epi ep110\n",
      "epi ep111\n",
      "epi ep112\n",
      "epi ep113\n",
      "epi ep114\n",
      "epi ep115\n",
      "epi ep116\n",
      "epi ep117\n",
      "epi ep118\n",
      "epi ep119\n",
      "epi ep120\n"
     ]
    }
   ],
   "source": [
    "from_path='./My_home.json'\n",
    "to_path='./CRECIL_train.json'\n",
    "vocab_file='/home/lr/h1k/KNN-BERT-main/csi_sequetial_fine_tuning/chinese_roberta_wwm_large_ext_pytorch/vocab.txt'\n",
    "bond_vocab=[671,7992]\n",
    "process(from_path,to_path,vocab_file,bond_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e54574f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cf3b4991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qwedfwdcsdasdcqq'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"qwedfwdcsdasdcq\"+\"q\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9236db2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 12 23:22:10 2024       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA RTX A6000    On   | 00000000:81:00.0 Off |                  Off |\r\n",
      "| 39%   66C    P2    98W / 300W |  35720MiB / 49140MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA RTX A6000    On   | 00000000:82:00.0 Off |                  Off |\r\n",
      "| 63%   84C    P2   290W / 300W |  15912MiB / 49140MiB |    100%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA RTX A6000    On   | 00000000:C1:00.0 Off |                  Off |\r\n",
      "| 45%   71C    P2   106W / 300W |  31168MiB / 49140MiB |     11%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  NVIDIA RTX A6000    On   | 00000000:C2:00.0 Off |                  Off |\r\n",
      "| 42%   67C    P2    94W / 300W |  30606MiB / 49140MiB |      2%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A    138421      C   python                          16290MiB |\r\n",
      "|    0   N/A  N/A    873231      C   python                          16958MiB |\r\n",
      "|    0   N/A  N/A   3956348      C   ...onda3/envs/mds/bin/python     2470MiB |\r\n",
      "|    1   N/A  N/A    682784      C   .../envs/python38/bin/python     3860MiB |\r\n",
      "|    1   N/A  N/A    940459      C   python                          12050MiB |\r\n",
      "|    2   N/A  N/A    943042      C   python3                         31166MiB |\r\n",
      "|    3   N/A  N/A    137937      C   python                           2728MiB |\r\n",
      "|    3   N/A  N/A    908741      C   python                          27876MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1939271e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
